
---

## ğŸ¬ Collaborative Filtering (CF)

**Collaborative Filtering** is a type of **recommender system** that predicts a userâ€™s interests
by learning from the **interactions between users and items** â€” for example, movie ratings, likes, or purchases.

Itâ€™s called *â€œcollaborativeâ€* because it uses the **collective behavior** of many users to make personalized recommendations.

---

### ğŸ§  Intuition

If two users have **rated similar movies similarly**,
then they likely share **similar preferences** â€” so one userâ€™s favorite movie can be recommended to the other.

Collaborative Filtering **doesnâ€™t need explicit features** of users or items.
It learns latent factors (hidden patterns) that explain preferences.

---

### âš™ï¸ The Setup

We start with a matrix ( Y ):

|            | Movie 1 | Movie 2 | Movie 3 | Movie 4 |
| :--------: | :-----: | :-----: | :-----: | :-----: |
| **User 1** |    5    |    ?    |    4    |    ?    |
| **User 2** |    3    |    2    |    ?    |    1    |
| **User 3** |    ?    |    4    |    5    |    ?    |

Goal â†’ Predict the missing entries (â€œ?â€).

---

### ğŸ”¢ Matrix Factorization Formulation

Collaborative Filtering models the rating matrix ( Y ) as the **product of two low-rank matrices**:

```
Y â‰ˆ X Ã— Wáµ€
```

Where:

* ( X ) â†’ item feature matrix (num_movies Ã— num_features)
* ( W ) â†’ user preference matrix (num_users Ã— num_features)
* ( b ) â†’ optional bias terms (user/movie averages)

The predicted rating:

```
Å·(i, j) = W_jáµ€ X_i + b_j
```

---

### ğŸ§® Cost Function

We minimize the **mean squared error** over all known ratings:

```
J(X, W, b) = Â½ Î£ ( (W_jáµ€ X_i + b_j - Y(i,j))Â² ) + (Î»/2)(||X||Â² + ||W||Â²)
```

where:

* Î» â†’ regularization parameter (to avoid overfitting)
* the sum is taken only over the rated (non-missing) entries.

---

### ğŸ” Training (Gradient Descent)

At each iteration:

```
X_i := X_i - Î± âˆ‚J/âˆ‚X_i
W_j := W_j - Î± âˆ‚J/âˆ‚W_j
```

Until convergence â€” when prediction error stabilizes.

---

### ğŸ§© Example with MovieLens Dataset

```python
import numpy as np
from sklearn.metrics import mean_squared_error
from surprise import SVD, Dataset, Reader

# Load the MovieLens 100k dataset
reader = Reader(line_format='user item rating timestamp', sep='\t')
data = Dataset.load_builtin('ml-100k')
trainset = data.build_full_trainset()

# Use SVD (a matrix factorization-based CF model)
model = SVD()
model.fit(trainset)

# Predict a single user-item rating
uid, iid = str(196), str(302)
pred = model.predict(uid, iid)
print(pred.est)
```

---

### ğŸ’¡ Practical Notes

| Concept                | Description                          |
| ---------------------- | ------------------------------------ |
| **Cold Start Problem** | New users/items have no history      |
| **Sparsity**           | Most users rate few items            |
| **Biases**             | Some users rate higher/lower overall |
| **Regularization**     | Prevents overfitting in sparse data  |

---

### ğŸš€ Summary

| Aspect               | Description                                                |
| -------------------- | ---------------------------------------------------------- |
| **Type**             | Recommender System                                         |
| **Goal**             | Predict missing preferences                                |
| **Approach**         | Learn latent user/item features                            |
| **Common Algorithm** | Matrix Factorization (SVD, ALS)                            |
| **Libraries**        | `surprise`, `lightfm`, `implicit`, TensorFlow Recommenders |

---

### ğŸ§© Visualization Concept (Optional)

If plotted, each user and item can be thought of as **points in the same latent space**:
close points â†’ higher predicted rating.

---

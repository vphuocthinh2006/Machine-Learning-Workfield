{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d86cf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3709f3f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>race/ethnicity</th>\n",
       "      <th>parental level of education</th>\n",
       "      <th>lunch</th>\n",
       "      <th>test preparation course</th>\n",
       "      <th>math score</th>\n",
       "      <th>reading score</th>\n",
       "      <th>writing score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>bachelor's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>group C</td>\n",
       "      <td>some college</td>\n",
       "      <td>standard</td>\n",
       "      <td>completed</td>\n",
       "      <td>69</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>group B</td>\n",
       "      <td>master's degree</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>90</td>\n",
       "      <td>95</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>group A</td>\n",
       "      <td>associate's degree</td>\n",
       "      <td>free/reduced</td>\n",
       "      <td>none</td>\n",
       "      <td>47</td>\n",
       "      <td>57</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>male</td>\n",
       "      <td>group C</td>\n",
       "      <td>some college</td>\n",
       "      <td>standard</td>\n",
       "      <td>none</td>\n",
       "      <td>76</td>\n",
       "      <td>78</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender race/ethnicity parental level of education         lunch  \\\n",
       "0  female        group B           bachelor's degree      standard   \n",
       "1  female        group C                some college      standard   \n",
       "2  female        group B             master's degree      standard   \n",
       "3    male        group A          associate's degree  free/reduced   \n",
       "4    male        group C                some college      standard   \n",
       "\n",
       "  test preparation course  math score  reading score  writing score  \n",
       "0                    none          72             72             74  \n",
       "1               completed          69             90             88  \n",
       "2                    none          90             95             93  \n",
       "3                    none          47             57             44  \n",
       "4                    none          76             78             75  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"spscientist/students-performance-in-exams\")\n",
    "data = pd.read_csv(os.path.join(path, \"StudentsPerformance.csv\"))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7bf9cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "math score       1.000000\n",
      "reading score    0.817580\n",
      "writing score    0.802642\n",
      "Name: math score, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Now, let's start with finding features that actually help us with deducting which feature is important\n",
    "numeric_data = data.select_dtypes(include=[np.number])\n",
    "correlation_matrix = numeric_data.corr()\n",
    "print(correlation_matrix[\"math score\"].sort_values(ascending=False))\n",
    "# So, math score is highly correlated with reading score and writing score. Let's use these two features to predict math score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6fe666d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[[\"reading score\", \"writing score\"]]\n",
    "y = data[\"math score\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "798b8e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e85a9dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression - MSE: 77.24297821278955, R2: 0.6825697127424626\n",
      "Linear Regression - Accuracy: 0.6825697127424626\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation with Linear Regression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Linear Regression - MSE: {mse}, R2: {r2}\")\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(f\"Linear Regression - Accuracy: {accuracy}\")\n",
    "\n",
    "#68% is not bad. Let's try Lasso Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a222791a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression - MSE: 77.28976844057277, R2: 0.6823774281388685\n",
      "Lasso Regression - Accuracy: 0.6823774281388685\n"
     ]
    }
   ],
   "source": [
    "model = Lasso(alpha=0.1)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test) \n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Lasso Regression - MSE: {mse}, R2: {r2}\")\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(f\"Lasso Regression - Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7356ab9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression - MSE: 77.2654829746764, R2: 0.6824772293453216\n",
      "Ridge Regression - Accuracy: 0.6824772293453216\n"
     ]
    }
   ],
   "source": [
    "model = Ridge(alpha=1.0)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Ridge Regression - MSE: {mse}, R2: {r2}\")\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(f\"Ridge Regression - Accuracy: {accuracy}\")\n",
    "# Still, everything is around 68%. Let's try another dataset. Why is this? Maybe the features are not good enough.\n",
    "# Maybe, we need more features to predict math score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b37ae318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's add in Polyminial Features\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_poly, y, test_size = 0.2, random_state = 42)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cbc7ce75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial Linear Regression - MSE: 75.90053253356909, R2: 0.6880864979240058\n",
      "Polynomial Linear Regression - Accuracy: 0.6880864979240058\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Polynomial Linear Regression - MSE: {mse}, R2: {r2}\")\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(f\"Polynomial Linear Regression - Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "32481a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression - MSE: 76.48855017942581, R2: 0.6856700373659652\n",
      "Ridge Regression - Accuracy: 0.6856700373659652\n"
     ]
    }
   ],
   "source": [
    "model = Ridge(alpha=1.0)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Ridge Regression - MSE: {mse}, R2: {r2}\")\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(f\"Ridge Regression - Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c3860df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression - MSE: 77.30140430341237, R2: 0.6823296105201138\n",
      "Lasso Regression - Accuracy: 0.6823296105201138\n"
     ]
    }
   ],
   "source": [
    "model = Lasso(alpha=0.1)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Lasso Regression - MSE: {mse}, R2: {r2}\")\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(f\"Lasso Regression - Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20d437d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

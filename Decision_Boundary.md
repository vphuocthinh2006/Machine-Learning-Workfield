
## üéØ Decision Boundary

A **decision boundary** is a surface that separates different classes in the feature space.  
It defines how a model decides **which class** a new data point belongs to, based on the learned parameters.

---

### üß† Intuition

For binary classification, a decision boundary is the line (or curve, or surface) where the model‚Äôs predicted probability equals 0.5.
$$
\[
\hat{y} = 
\begin{cases}
1, & \text{if } P(y=1|x) \ge 0.5 \\
0, & \text{otherwise}
\end{cases}
\]
$$
For **Linear Models** like Logistic Regression, this boundary is a **straight line (2D)** or **hyperplane (nD)**:

\[
w_1x_1 + w_2x_2 + b = 0
\]

If your data can be linearly separated, the model finds this plane to distinguish classes.

---

### üåà Example Visualization

Imagine a dataset with two features, \( x_1 \) and \( x_2 \).  

- Points labeled **blue** = class 0  
- Points labeled **red** = class 1  
- The line between them is the **decision boundary**



(visualize using matplotlib + seaborn)

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LogisticRegression

# Create synthetic data
np.random.seed(0)
X = np.random.randn(100, 2)
y = (X[:, 0] + X[:, 1] > 0).astype(int)

# Train logistic regression
model = LogisticRegression().fit(X, y)

# Plot
x_min, x_max = X[:, 0].min()-1, X[:, 0].max()+1
y_min, y_max = X[:, 1].min()-1, X[:, 1].max()+1
xx, yy = np.meshgrid(np.linspace(x_min, x_max, 200),
                     np.linspace(y_min, y_max, 200))
Z = model.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)

plt.contourf(xx, yy, Z, alpha=0.3, cmap='RdBu')
plt.scatter(X[:, 0], X[:, 1], c=y, s=30, cmap='RdBu', edgecolors='k')
plt.title("Decision Boundary - Logistic Regression")
plt.xlabel("x‚ÇÅ")
plt.ylabel("x‚ÇÇ")
plt.show()
```

---

### üß© Nonlinear Decision Boundaries

Linear models can only create **straight-line** boundaries.
To separate data with **complex patterns**, we need algorithms that can bend or partition the space ‚Äî such as:

| Algorithm             | Boundary Type    | Note                |
| --------------------- | ---------------- | ------------------- |
| Logistic Regression   | Linear           | Cannot model curves |
| Polynomial Regression | Curved           | Adds feature powers |
| Decision Trees        | Piecewise-linear | Axis-aligned splits |
| SVM (RBF Kernel)      | Smooth nonlinear | Uses kernel trick   |
| Neural Networks       | Arbitrary        | Highly flexible     |

---

### üöÄ Summary

* A **decision boundary** is the region where a model changes its prediction from one class to another.
* Linear models ‚Üí straight boundaries
* Nonlinear models ‚Üí curved or piecewise boundarie
* Understanding this concept helps visualize **how models ‚Äúthink‚Äù** and what kind of data they can separate.

---


